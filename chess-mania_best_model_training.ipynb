{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gQTPoALMeq_H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import chess\n",
        "\n",
        "def board_to_array(fen):\n",
        "    board = chess.Board(fen)\n",
        "    piece_dict = {'P': 1, 'N': 2, 'B': 3, 'R': 4, 'Q': 5, 'K': 6,\n",
        "                  'p': -1, 'n': -2, 'b': -3, 'r': -4, 'q': -5, 'k': -6}\n",
        "    array = np.zeros((8, 8), dtype=np.int8)\n",
        "    for i in range(64):\n",
        "        piece = board.piece_at(i)\n",
        "        if piece:\n",
        "            array[i // 8][i % 8] = piece_dict[piece.symbol()]\n",
        "    return array\n",
        "\n",
        "def move_to_index(move):\n",
        "    # Extract just the 'from' and 'to' squares, ignoring promotion\n",
        "    from_square = move[:2]\n",
        "    to_square = move[2:4]\n",
        "    return chess.SQUARE_NAMES.index(from_square) * 64 + chess.SQUARE_NAMES.index(to_square)\n",
        "\n",
        "# Load the data\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/train-an-ai-to-play-chess/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/train-an-ai-to-play-chess/test.csv')\n",
        "\n",
        "\n",
        "# Preprocess training data\n",
        "X_train = np.array([board_to_array(board) for board in train_df['board']])\n",
        "y_train_score = np.array(train_df['black_score'])\n",
        "y_train_move = np.array([move_to_index(move) for move in train_df['best_move']])\n",
        "\n",
        "# Preprocess test data\n",
        "X_test = np.array([board_to_array(board) for board in test_df['board']])\n",
        "\n",
        "# Reshape input data for the neural network\n",
        "X_train = X_train.reshape((-1, 8, 8, 1))\n",
        "X_test = X_test.reshape((-1, 8, 8, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtOqSGcOgOtW",
        "outputId": "0c006adf-e45d-45ab-9ae9-9b746f1e3fa5"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries (optional, in case they're not already installed in Colab)\n",
        "!pip install tensorflow chess pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import chess\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, Flatten, Dense, Reshape, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "# Set up mixed precision for better GPU performance\n",
        "set_global_policy('mixed_float16')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6VZDxFuqgSq6"
      },
      "outputs": [],
      "source": [
        "def residual_block(x, filters, kernel_size=3):\n",
        "    y = Conv2D(filters, kernel_size, padding=\"same\", kernel_regularizer=l2(1e-4))(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation(\"relu\")(y)\n",
        "    y = Conv2D(filters, kernel_size, padding=\"same\", kernel_regularizer=l2(1e-4))(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    return Add()([x, y])\n",
        "\n",
        "def create_improved_model():\n",
        "    board_input = Input(shape=(8, 8, 12))\n",
        "    meta_input = Input(shape=(7,))\n",
        "\n",
        "    # Initial convolutional layer\n",
        "    x = Conv2D(256, 3, padding=\"same\", kernel_regularizer=l2(1e-4))(board_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(19):\n",
        "        x = residual_block(x, 256)\n",
        "\n",
        "    # Policy head\n",
        "    policy = Conv2D(256, 1, kernel_regularizer=l2(1e-4))(x)\n",
        "    policy = BatchNormalization()(policy)\n",
        "    policy = Activation(\"relu\")(policy)\n",
        "    policy = Flatten()(policy)\n",
        "    policy = Dense(4096, activation=\"softmax\", kernel_regularizer=l2(1e-4), name=\"policy\")(policy)\n",
        "\n",
        "    # Value head\n",
        "    value = Conv2D(1, 1, kernel_regularizer=l2(1e-4))(x)\n",
        "    value = BatchNormalization()(value)\n",
        "    value = Activation(\"relu\")(value)\n",
        "    value = Flatten()(value)\n",
        "    value = Dense(256, activation=\"relu\", kernel_regularizer=l2(1e-4))(value)\n",
        "    value = Concatenate()([value, meta_input])\n",
        "    value = Dense(1, activation=\"tanh\", kernel_regularizer=l2(1e-4), name=\"value\")(value)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=[board_input, meta_input], outputs=[policy, value])\n",
        "\n",
        "    # Compile model with mixed precision and loss scale optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss={\"policy\": \"categorical_crossentropy\", \"value\": \"mean_squared_error\"},\n",
        "        metrics={\"policy\": \"accuracy\", \"value\": \"mae\"}\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T-kbzvm0gWxA"
      },
      "outputs": [],
      "source": [
        "def board_to_planes(fen):\n",
        "    board = chess.Board(fen)\n",
        "    planes = np.zeros((8, 8, 12), dtype=np.float32)\n",
        "    piece_dict = {\n",
        "        'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
        "        'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
        "    }\n",
        "    for i in range(64):\n",
        "        piece = board.piece_at(i)\n",
        "        if piece:\n",
        "            planes[i // 8, i % 8, piece_dict[piece.symbol()]] = 1\n",
        "    return planes\n",
        "\n",
        "def get_meta_features(fen):\n",
        "    board = chess.Board(fen)\n",
        "    return np.array([\n",
        "        int(board.has_kingside_castling_rights(chess.WHITE)),\n",
        "        int(board.has_queenside_castling_rights(chess.WHITE)),\n",
        "        int(board.has_kingside_castling_rights(chess.BLACK)),\n",
        "        int(board.has_queenside_castling_rights(chess.BLACK)),\n",
        "        int(board.has_legal_en_passant()),\n",
        "        board.halfmove_clock / 100.0,\n",
        "        board.fullmove_number / 100.0\n",
        "    ], dtype=np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dhqN_eJrgYnQ"
      },
      "outputs": [],
      "source": [
        "def data_generator(df, batch_size=32):\n",
        "    def gen():\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            batch_df = df.iloc[i:i+batch_size]\n",
        "            X_board = np.array([board_to_planes(fen) for fen in batch_df['board']])\n",
        "            X_meta = np.array([get_meta_features(fen) for fen in batch_df['board']])\n",
        "\n",
        "            if 'black_score' in batch_df.columns:\n",
        "                y_value = np.array(batch_df['black_score'])\n",
        "            else:\n",
        "                y_value = np.zeros(len(batch_df))\n",
        "\n",
        "            y_policy = np.ones((len(batch_df), 4096)) / 4096\n",
        "\n",
        "            yield (\n",
        "                (tf.convert_to_tensor(X_board, dtype=tf.float32),\n",
        "                 tf.convert_to_tensor(X_meta, dtype=tf.float32)),\n",
        "                (tf.convert_to_tensor(y_policy, dtype=tf.float32),\n",
        "                 tf.convert_to_tensor(y_value, dtype=tf.float32))\n",
        "            )\n",
        "\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        output_signature=(\n",
        "            (tf.TensorSpec(shape=(None, 8, 8, 12), dtype=tf.float32),\n",
        "             tf.TensorSpec(shape=(None, 7), dtype=tf.float32)),\n",
        "            (tf.TensorSpec(shape=(None, 4096), dtype=tf.float32),\n",
        "             tf.TensorSpec(shape=(None,), dtype=tf.float32))\n",
        "        )\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iH0oYnDgad2",
        "outputId": "d9092c7f-924b-4056-faa5-a9862fb6bd3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "    919/Unknown \u001b[1m148s\u001b[0m 93ms/step - loss: 159975.3594 - policy_accuracy: 4.7429e-05 - value_mae: 274.9948"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 106ms/step - loss: 159979.3906 - policy_accuracy: 4.7396e-05 - value_mae: 274.9961 - val_loss: 10.5510 - val_policy_accuracy: 0.0000e+00 - val_value_mae: 0.9634\n",
            "Epoch 2/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 66ms/step - loss: 159916.4062 - policy_accuracy: 0.0000e+00 - value_mae: 274.9314 - val_loss: 10.7788 - val_policy_accuracy: 0.0000e+00 - val_value_mae: 0.9789\n",
            "Epoch 3/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 69ms/step - loss: 159911.5938 - policy_accuracy: 2.4431e-04 - value_mae: 274.9241 - val_loss: 11.0397 - val_policy_accuracy: 0.0000e+00 - val_value_mae: 0.9782\n",
            "Epoch 4/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 70ms/step - loss: 159903.3906 - policy_accuracy: 0.0000e+00 - value_mae: 274.9164 - val_loss: 11.5471 - val_policy_accuracy: 0.0000e+00 - val_value_mae: 0.9927\n",
            "Epoch 5/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 70ms/step - loss: 159888.7812 - policy_accuracy: 0.0130 - value_mae: 274.8957 - val_loss: 11.9470 - val_policy_accuracy: 0.0000e+00 - val_value_mae: 0.9901\n",
            "Epoch 6/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 70ms/step - loss: 159888.5938 - policy_accuracy: 0.0056 - value_mae: 274.9091 - val_loss: 12.4606 - val_policy_accuracy: 0.0000e+00 - val_value_mae: 0.9944\n",
            "Epoch 7/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 69ms/step - loss: 159872.2500 - policy_accuracy: 0.0068 - value_mae: 274.8828 - val_loss: 12.9941 - val_policy_accuracy: 0.0050 - val_value_mae: 0.9767\n",
            "Epoch 8/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 69ms/step - loss: 159873.7344 - policy_accuracy: 0.2457 - value_mae: 274.8957 - val_loss: 13.4714 - val_policy_accuracy: 1.0000 - val_value_mae: 0.9629\n",
            "Epoch 9/100\n",
            "\u001b[1m919/919\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 68ms/step - loss: 159860.0781 - policy_accuracy: 0.9994 - value_mae: 274.8851 - val_loss: 13.9611 - val_policy_accuracy: 1.0000 - val_value_mae: 0.9853\n",
            "Epoch 10/100\n",
            "\u001b[1m571/919\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 68ms/step - loss: 157539.9375 - policy_accuracy: 1.0000 - value_mae: 273.9359"
          ]
        }
      ],
      "source": [
        "# Assume train_df and test_df are pandas DataFrames that you've already prepared.\n",
        "# Replace these with the actual DataFrame variables you're using.\n",
        "train_gen = data_generator(train_df, batch_size=64)\n",
        "val_gen = data_generator(test_df, batch_size=64)\n",
        "\n",
        "# Create and train the improved model\n",
        "improved_model = create_improved_model()\n",
        "\n",
        "# Train the model\n",
        "history = improved_model.fit(\n",
        "    train_gen,\n",
        "    epochs=100,\n",
        "    validation_data=val_gen\n",
        ")\n",
        "\n",
        "# Save the improved model\n",
        "improved_model.save('improved_chess_ai_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-p6VxjGghF-"
      },
      "outputs": [],
      "source": [
        "# Function to play a game and export PGN\n",
        "def play_game_with_improved_model(model, max_moves=50):\n",
        "    board = chess.Board()\n",
        "    move_count = 0\n",
        "\n",
        "    # Track the moves in PGN format\n",
        "    game_moves = []\n",
        "\n",
        "    while not board.is_game_over() and move_count < max_moves:\n",
        "        print(f\"Move {move_count + 1}\")\n",
        "        print(board)\n",
        "\n",
        "        if board.turn == chess.WHITE:\n",
        "            move = predict_move_improved(model, board)\n",
        "            try:\n",
        "                board.push_uci(move)\n",
        "            except chess.IllegalMoveError:\n",
        "                print(f\"AI attempted illegal move: {move}. Choosing random move.\")\n",
        "                legal_moves = list(board.legal_moves)\n",
        "                if legal_moves:\n",
        "                    board.push(np.random.choice(legal_moves))\n",
        "                else:\n",
        "                    print(\"No legal moves available. Game over.\")\n",
        "                    break\n",
        "        else:\n",
        "            # Simulate black's random move\n",
        "            legal_moves = list(board.legal_moves)\n",
        "            if legal_moves:\n",
        "                board.push(np.random.choice(legal_moves))\n",
        "            else:\n",
        "                print(\"No legal moves available. Game over.\")\n",
        "                break\n",
        "\n",
        "        # Add the move to the game_moves list in PGN format\n",
        "        game_moves.append(board.san(board.peek()))\n",
        "\n",
        "        move_count += 1\n",
        "        print(\"\\n\")\n",
        "\n",
        "    print(board)\n",
        "    print(\"Game over\")\n",
        "\n",
        "    # Export the game as PGN\n",
        "    game_pgn = board.board_fen() + \"\\n\\n\"\n",
        "    for i, move in enumerate(game_moves):\n",
        "        if i % 2 == 0:\n",
        "            game_pgn += f\"{(i // 2) + 1}. {move} \"\n",
        "        else:\n",
        "            game_pgn += f\"{move} \"\n",
        "\n",
        "    print(\"Result:\", board.result())\n",
        "    print(\"\\nPGN Format:\")\n",
        "    print(game_pgn)\n",
        "\n",
        "    return game_pgn\n",
        "\n",
        "# Play the game and get the PGN\n",
        "pgn_output = play_game_with_improved_model(improved_model)\n",
        "\n",
        "# Save the PGN to a file\n",
        "with open('chess_game.pgn', 'w') as f:\n",
        "    f.write(pgn_output)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
